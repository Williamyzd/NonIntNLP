from dataloaders.remote.data_processors import DataProcessor

class DataServer:
    def __init__(self):
        pass

    def create_session(self, model_name=str, max_sequence_size=int):
        pass

    def get_quantity_for_filter(self, session):
        pass

    def get_next(self, session_id=str):
        pass

# Represents a single session for pulling data from a live DataServer. You will build a session with a set of filters
# and a configuration which defines how the data it outputs will be formatted, and then iterate through it. A session
# lives and dies with your client program.
class DataSession:

    # Initialize the given session. This should be called by DataServer.create_session() - not by clients.
    def __init__(self, session_id=str, server=DataServer, model_name=str, max_sequence_size=int):
        self.session_id = session_id
        self.server = server
        self.model_name = model_name

        # Internal state variables.
        self.data_sources = []
        self.data_types = []
        self.processor = DataProcessor(model_name, max_sequence_size)
        self.is_allocated = False
        self.next_allocated = None
        self.counter = 0
        self.started = False
        self.requested_size = 0
        self.batch_size = 0

    # Filters the outputs of this session to the specified data_sources.
    def select_sources(self, data_sources=list):
        if self.started:
            raise EnvironmentError("Cannot change the data selections of a session that has not been started.")
        self.data_sources = data_sources

    # Filters the outputs of the session to the specified data_types.
    def select_types(self, data_types=list):
        if self.started:
            raise EnvironmentError("Cannot change the data selections of a session that has not been started.")
        self.data_types = data_types

    # Sets a language modeling scheme which determines how to process data that does not have an explicit label.
    # By default, the t5 scheme is used. To see the available schemes, take a look at language_modelers.py.
    def set_language_modeling_scheme(self, scheme=str):
        self.processor.set_lm_scheme(scheme)

    # Configures what fields will be outputted on every get_next() call:
    #  attention_masks='attention_masks' field, 0 for all <pad> tokens, 1 for everything else.
    #  token_types='token_type_ids' field, set to 0 for the primary sequence, 1 for the secondary, etc. Omit this if you
    #                                      are only pulling types with a primary sequence.
    #  labels='labels' field, always set to a language model target. If the underlying data item has a specified label
    #         string or integer - that is used, encoded as a string. Otherwise the label will be generated by the
    #         active language modeling scheme (set_language_modeling_scheme).
    #  decoder_inputs=When true, 'decoder_' outputs will also be generated and sent.
    def set_fields_to_output(self, attention_masks=False, token_types=False, labels=False, decoder_inputs=False):
        self.processor.set_fields(attention_masks, token_types, labels, decoder_inputs)

    # Returns the total number of database rows match the filters you have selected. Note that since many items are
    # well above the specified sequence_size limit, the total amount of data you can fetch is much higher than this.
    # Unfortunately, there is not a good way to calculate this bound without iterating through the entire set, so you
    # will need to guess.
    def get_quantity_selected(self):
        return self.server.get_quantity_for_filter()

    # Locks in your data filter selections and configures how get_next() will behave.
    # task_pool_size=Maximum number of sequences to return before requiring a reset.
    # batch_size=Number of sequences to group together in each get_next().
    #
    # Also allocates one batch of specified size to be immediately returned on the following get_next() call.
    def start(self, task_pool_size=int, batch_size=int):
        if batch_size > task_pool_size:
            raise EnvironmentError("Batch size must be smaller than requested total size.")
        self.started = True
        self.counter = 0
        self.requested_size = task_pool_size
        self.batch_size = batch_size
        self.alloc_next()

    def reset(self):
        self.counter = 0

    def alloc_next(self):
        if self.is_allocated:
            print("DataServer warning: Session.alloc_next() was called twice without an intermediary get_next().")
            return
        if not self.started:
            raise EnvironmentError("Must call start() before alloc_next() or get_next().")
        row = self.server.get_next(self.session_id)
        self.next_allocated = self.processor.process_row(row)
        self.is_allocated = True

    def get_next(self):
        if self.counter >= self.requested_size:
            raise EnvironmentError("Requested more data than was originally allocated.")
        if not self.is_allocated:
            print("DataServer warning: Session.get_next() was called without a preceding alloc_next(). This will cause"
                  "significant performance problems.")
            self.alloc_next()
        self.is_allocated = False
        return self.next_allocated