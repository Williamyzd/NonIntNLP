{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import wandb\n",
    "import time\n",
    "import orjson\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import glue_convert_examples_to_features as convert_examples_to_features\n",
    "from transformers import glue_output_modes as output_modes\n",
    "from transformers import glue_processors as processors\n",
    "\n",
    "fp16 = True\n",
    "if fp16:\n",
    "    from apex import amp\n",
    "\n",
    "model_name = \"albert-large-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load a sentiment review dataset.\n",
    "def split_inputs_and_outputs(data_map):\n",
    "    return [torch.tensor(np.asarray(data_map['input_id']), dtype=torch.long),\n",
    "           torch.tensor(np.asarray(data_map['attention_mask']), dtype=torch.float),\n",
    "           torch.tensor(np.asarray(data_map['token_type_id']), dtype=torch.long)],\\\n",
    "           torch.tensor(np.asarray(data_map['label']), dtype=torch.float)\n",
    "\n",
    "def split_inputs_and_outputs_distil(data_map):\n",
    "    return [torch.tensor(np.asarray(data_map['input_id']), dtype=torch.long),\n",
    "           torch.tensor(np.asarray(data_map['attention_mask']), dtype=torch.float)],\\\n",
    "           torch.tensor(np.asarray(data_map['label']), dtype=torch.float)\n",
    "\n",
    "def split_inputs_and_outputs_gpt2(data_map):\n",
    "    return torch.tensor(np.asarray(data_map['input_id']), dtype=torch.long),\\\n",
    "           torch.tensor(np.asarray(data_map['label']), dtype=torch.float)\n",
    "\n",
    "def load_data(train_filename, val_filename, ldr_fn):\n",
    "    training_data = orjson.loads(open(train_filename, \"rb\").read())\n",
    "    train_x, train_y = ldr_fn(training_data)\n",
    "    val_data = orjson.loads(open(val_filename, \"rb\").read())\n",
    "    val_x, val_y = ldr_fn(val_data)\n",
    "    return TensorDataset(train_x[0], train_x[1], train_x[2], train_y), TensorDataset(val_x[0], val_x[1], val_x[2], val_y)\n",
    "\n",
    "# Load data.\n",
    "train_dataset_path = \"C:/Users/jbetk/Documents/data/ml/sentiment_analysis/outputs/albert/processed.json\"\n",
    "val_dataset_path = \"C:/Users/jbetk/Documents/data/ml/sentiment_analysis/outputs/albert/validation.json\"\n",
    "train_dataset, val_dataset = load_data(train_dataset_path, val_dataset_path, split_inputs_and_outputs)\n",
    "\n",
    "# Use regression loss\n",
    "num_labels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a7d601260c59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocessors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#train_dataset = load_dataset(processor.get_train_examples(input_file), processor)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mval_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_msrp_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dev_examples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-a7d601260c59>\u001b[0m in \u001b[0;36mload_msrp_dataset\u001b[1;34m(examples, processor)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtoken_type_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_type_ids\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Process dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-a7d601260c59>\u001b[0m in \u001b[0;36mload_msrp_dataset\u001b[1;34m(examples, processor)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtoken_type_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_type_ids\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Process dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_36_64.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_36_64.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_36_64.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_36_64.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_36_64.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_36_64.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_36_64.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_36_64.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_36_64.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_36_64.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\JetBrains\\PyCharm 2019.3.1\\plugins\\python\\helpers\\pydev\\pydevd.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_threads_suspended_single_notification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify_thread_suspended\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthread_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_reason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_wait_suspend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_wait_suspend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\JetBrains\\PyCharm 2019.3.1\\plugins\\python\\helpers\\pydev\\pydevd.py\u001b[0m in \u001b[0;36m_do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_internal_commands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcancel_async_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_current_thread_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load a semantic comparison dataset (MSRPC)\n",
    "tokenizer = transformers.AlbertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def load_msrp_dataset(examples, processor):\n",
    "    output_mode = output_modes[task]\n",
    "    label_list = processor.get_labels()\n",
    "    features = convert_examples_to_features(examples, \n",
    "                                            tokenizer, \n",
    "                                            label_list=label_list,\n",
    "                                            max_length=128,\n",
    "                                            pad_on_left=False,\n",
    "                                            output_mode=output_mode,\n",
    "                                            pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "                                            pad_token_segment_id=0)\n",
    "    input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "    token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
    "    labels = torch.tensor([f.label for f in features], dtype=torch.long)\n",
    "    return TensorDataset(input_ids, attention_mask, token_type_ids, labels)\n",
    "\n",
    "# Process dataset\n",
    "task = 'mrpc'\n",
    "input_file = \"C:\\\\Users\\\\jbetk\\\\Documents\\\\data\\\\ml\\\\text_similarity\\\\MSRParaphraseCorpus\"\n",
    "processor = processors[task]()\n",
    "train_dataset = load_dataset(processor.get_train_examples(input_file), processor)\n",
    "val_dataset = load_msrp_dataset(processor.get_dev_examples(input_file), processor)\n",
    "\n",
    "num_labels=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/neonbjb/nonint-transformers-torch\" target=\"_blank\">https://app.wandb.ai/neonbjb/nonint-transformers-torch</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/neonbjb/nonint-transformers-torch/runs/tcl01e2d\" target=\"_blank\">https://app.wandb.ai/neonbjb/nonint-transformers-torch/runs/tcl01e2d</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "config = transformers.AlbertConfig.from_pretrained(model_name)\n",
    "config.num_labels = num_labels\n",
    "model = transformers.AlbertForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "device = torch.device(\"cuda\")\n",
    "cpu = torch.device(\"cpu\")\n",
    "\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0,\n",
    "    },\n",
    "    {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "]\n",
    "#print(\"Parameters: \", optimizer_grouped_parameters)\n",
    "optimizer = transformers.AdamW(optimizer_grouped_parameters, lr=2e-5, eps=1e-8)\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer, \n",
    "                                                         num_warmup_steps=0, num_training_steps=len(train_dataset))\n",
    "\n",
    "# Shift model to cuda & enable fp16 if applicable.\n",
    "model.to(device)\n",
    "if fp16:\n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n",
    "    \n",
    "# Initialize w&b logger\n",
    "do_wandb = True\n",
    "if do_wandb:\n",
    "    wandb.init(project=\"nonint-transformers-torch\",\\\n",
    "               name=\"albert_sentiment_analysis_torch\",\\\n",
    "               config={\"dataset\": \"sent_amazon_yelp\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2625860\n",
      "  Num Epochs = 2\n",
      "  Total optimization steps = 2625860\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "\n",
      "\n",
      "Validation loss 0.432338, accuracy=0.000000\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "\n",
      "\n",
      "Validation loss 0.382829, accuracy=0.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbfcd5487384d8b8048286a8cdb3cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=109411.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "requests_with_retry encountered retryable exception: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None)). args: ('https://api.wandb.ai/files/neonbjb/nonint-transformers-torch/tcl01e2d/file_stream',), kwargs: {'json': {'files': {'wandb-history.jsonl': {'offset': 9352, 'content': ['{\"loss\": 0.36578323841094973, \"accuracy\": 0.0, \"learning_rate\": 1.9643773849329365e-05, \"_runtime\": 20612.412152528763, \"_timestamp\": 1583732541.9383655, \"_step\": 9352}\\n', '{\"loss\": 0.40464792847633363, \"accuracy\": 0.0, \"learning_rate\": 1.9643735766567906e-05, \"_runtime\": 20614.615302562714, \"_timestamp\": 1583732544.1415155, \"_step\": 9353}\\n', '{\"loss\": 0.5400665819644928, \"accuracy\": 0.0, \"learning_rate\": 1.964369768380645e-05, \"_runtime\": 20616.81369972229, \"_timestamp\": 1583732546.3399127, \"_step\": 9354}\\n', '{\"loss\": 0.7095645546913147, \"accuracy\": 0.0, \"learning_rate\": 1.9643659601044992e-05, \"_runtime\": 20619.008776903152, \"_timestamp\": 1583732548.5349898, \"_step\": 9355}\\n', '{\"loss\": 0.6075250655412674, \"accuracy\": 0.0, \"learning_rate\": 1.9643621518283536e-05, \"_runtime\": 20621.221212148666, \"_timestamp\": 1583732550.747425, \"_step\": 9356}\\n', '{\"loss\": 0.6687017142772674, \"accuracy\": 0.0, \"learning_rate\": 1.9643583435522078e-05, \"_runtime\": 20623.42423939705, \"_timestamp\": 1583732552.9504523, \"_step\": 9357}\\n', '{\"loss\": 0.6613329887390137, \"accuracy\": 0.0, \"learning_rate\": 1.964354535276062e-05, \"_runtime\": 20625.633752822876, \"_timestamp\": 1583732555.1599658, \"_step\": 9358}\\n', '{\"loss\": 0.33713625073432923, \"accuracy\": 0.0, \"learning_rate\": 1.9643507269999164e-05, \"_runtime\": 20627.85578560829, \"_timestamp\": 1583732557.3819985, \"_step\": 9359}\\n', '{\"loss\": 0.4316514194011688, \"accuracy\": 0.0, \"learning_rate\": 1.9643469187237708e-05, \"_runtime\": 20630.05229449272, \"_timestamp\": 1583732559.5785074, \"_step\": 9360}\\n', '{\"loss\": 0.42796874046325684, \"accuracy\": 0.0, \"learning_rate\": 1.964343110447625e-05, \"_runtime\": 20632.257728099823, \"_timestamp\": 1583732561.783941, \"_step\": 9361}\\n', '{\"loss\": 0.5734193742275238, \"accuracy\": 0.0, \"learning_rate\": 1.964339302171479e-05, \"_runtime\": 20634.453600168228, \"_timestamp\": 1583732563.979813, \"_step\": 9362}\\n', '{\"loss\": 0.40369810461997985, \"accuracy\": 0.0, \"learning_rate\": 1.9643354938953335e-05, \"_runtime\": 20636.65538597107, \"_timestamp\": 1583732566.181599, \"_step\": 9363}\\n', '{\"loss\": 0.4932340681552887, \"accuracy\": 0.0, \"learning_rate\": 1.964331685619188e-05, \"_runtime\": 20638.869101285934, \"_timestamp\": 1583732568.3953142, \"_step\": 9364}\\n', '{\"loss\": 0.46664859652519225, \"accuracy\": 0.0, \"learning_rate\": 1.964327877343042e-05, \"_runtime\": 20641.10059785843, \"_timestamp\": 1583732570.6268108, \"_step\": 9365}\\n']}, 'wandb-summary.json': {'offset': 0, 'content': ['{\"accuracy\": 0.0, \"_timestamp\": 1583732570.6268108, \"learning_rate\": 1.964327877343042e-05, \"loss\": 0.46664859652519225, \"_runtime\": 20641.10059785843, \"_step\": 9365}\\n']}}}}\n",
      "requests_with_retry encountered retryable exception: 500 Server Error: Internal Server Error for url: https://api.wandb.ai/files/neonbjb/nonint-transformers-torch/tcl01e2d/file_stream. args: ('https://api.wandb.ai/files/neonbjb/nonint-transformers-torch/tcl01e2d/file_stream',), kwargs: {'json': {'files': {'wandb-events.jsonl': {'offset': 937, 'content': ['{\"system.gpu.0.gpu\": 80.8, \"system.gpu.0.memory\": 57.47, \"system.gpu.0.memoryAllocated\": 92.13, \"system.gpu.0.temp\": 63.47, \"system.gpu.0.powerWatts\": 245.67, \"system.gpu.0.powerPercent\": 98.27, \"system.cpu\": 13.29, \"system.memory\": 26.39, \"system.disk\": 77.7, \"system.proc.memory.availableMB\": 48181.82, \"system.proc.memory.rssMB\": 7680.13, \"system.proc.memory.percent\": 11.74, \"system.proc.cpu.threads\": 60.0, \"system.network.sent\": 1243763939, \"system.network.recv\": 967369466, \"_wandb\": true, \"_timestamp\": 1583740544, \"_runtime\": 28754}\\n']}, 'wandb-history.jsonl': {'offset': 12981, 'content': ['{\"loss\": 0.6114494442939759, \"accuracy\": 0.0, \"learning_rate\": 1.950557150800119e-05, \"_runtime\": 28585.670660972595, \"_timestamp\": 1583740515.196874, \"_step\": 12981}\\n', '{\"loss\": 0.576430594921112, \"accuracy\": 0.0, \"learning_rate\": 1.9505533425239733e-05, \"_runtime\": 28587.852586746216, \"_timestamp\": 1583740517.3787997, \"_step\": 12982}\\n', '{\"loss\": 0.3163151144981384, \"accuracy\": 0.0, \"learning_rate\": 1.9505495342478275e-05, \"_runtime\": 28590.035104751587, \"_timestamp\": 1583740519.5613177, \"_step\": 12983}\\n', '{\"loss\": 0.4993768870830536, \"accuracy\": 0.0, \"learning_rate\": 1.950545725971682e-05, \"_runtime\": 28592.222602128983, \"_timestamp\": 1583740521.748815, \"_step\": 12984}\\n', '{\"loss\": 0.30545700192451475, \"accuracy\": 0.0, \"learning_rate\": 1.950541917695536e-05, \"_runtime\": 28594.38809609413, \"_timestamp\": 1583740523.914309, \"_step\": 12985}\\n', '{\"loss\": 0.5104227840900422, \"accuracy\": 0.0, \"learning_rate\": 1.9505381094193905e-05, \"_runtime\": 28596.569601535797, \"_timestamp\": 1583740526.0958145, \"_step\": 12986}\\n', '{\"loss\": 0.5495247483253479, \"accuracy\": 0.0, \"learning_rate\": 1.9505343011432446e-05, \"_runtime\": 28598.76362991333, \"_timestamp\": 1583740528.2898428, \"_step\": 12987}\\n', '{\"loss\": 0.3636123687028885, \"accuracy\": 0.0, \"learning_rate\": 1.950530492867099e-05, \"_runtime\": 28600.941640853882, \"_timestamp\": 1583740530.4678538, \"_step\": 12988}\\n', '{\"loss\": 0.3498614400625229, \"accuracy\": 0.0, \"learning_rate\": 1.9505266845909532e-05, \"_runtime\": 28603.12463402748, \"_timestamp\": 1583740532.650847, \"_step\": 12989}\\n', '{\"loss\": 0.29560511112213134, \"accuracy\": 0.0, \"learning_rate\": 1.9505228763148074e-05, \"_runtime\": 28605.303024291992, \"_timestamp\": 1583740534.8292372, \"_step\": 12990}\\n', '{\"loss\": 0.3160191774368286, \"accuracy\": 0.0, \"learning_rate\": 1.9505190680386618e-05, \"_runtime\": 28607.465535640717, \"_timestamp\": 1583740536.9917486, \"_step\": 12991}\\n', '{\"loss\": 0.5232029914855957, \"accuracy\": 0.0, \"learning_rate\": 1.950515259762516e-05, \"_runtime\": 28609.64454483986, \"_timestamp\": 1583740539.1707578, \"_step\": 12992}\\n', '{\"loss\": 0.3517184555530548, \"accuracy\": 0.0, \"learning_rate\": 1.9505114514863704e-05, \"_runtime\": 28611.82610154152, \"_timestamp\": 1583740541.3523145, \"_step\": 12993}\\n', '{\"loss\": 0.4365436315536499, \"accuracy\": 0.0, \"learning_rate\": 1.9505076432102245e-05, \"_runtime\": 28614.008598804474, \"_timestamp\": 1583740543.5348117, \"_step\": 12994}\\n']}, 'wandb-summary.json': {'offset': 0, 'content': ['{\"accuracy\": 0.0, \"_timestamp\": 1583740543.5348117, \"learning_rate\": 1.9505076432102245e-05, \"loss\": 0.4365436315536499, \"_runtime\": 28614.008598804474, \"_step\": 12994}\\n']}}}}\n",
      "requests_with_retry encountered retryable exception: 500 Server Error: Internal Server Error for url: https://api.wandb.ai/files/neonbjb/nonint-transformers-torch/tcl01e2d/file_stream. args: ('https://api.wandb.ai/files/neonbjb/nonint-transformers-torch/tcl01e2d/file_stream',), kwargs: {'json': {'files': {'wandb-events.jsonl': {'offset': 937, 'content': ['{\"system.gpu.0.gpu\": 80.8, \"system.gpu.0.memory\": 57.47, \"system.gpu.0.memoryAllocated\": 92.13, \"system.gpu.0.temp\": 63.47, \"system.gpu.0.powerWatts\": 245.67, \"system.gpu.0.powerPercent\": 98.27, \"system.cpu\": 13.29, \"system.memory\": 26.39, \"system.disk\": 77.7, \"system.proc.memory.availableMB\": 48181.82, \"system.proc.memory.rssMB\": 7680.13, \"system.proc.memory.percent\": 11.74, \"system.proc.cpu.threads\": 60.0, \"system.network.sent\": 1243763939, \"system.network.recv\": 967369466, \"_wandb\": true, \"_timestamp\": 1583740544, \"_runtime\": 28754}\\n']}, 'wandb-history.jsonl': {'offset': 12981, 'content': ['{\"loss\": 0.6114494442939759, \"accuracy\": 0.0, \"learning_rate\": 1.950557150800119e-05, \"_runtime\": 28585.670660972595, \"_timestamp\": 1583740515.196874, \"_step\": 12981}\\n', '{\"loss\": 0.576430594921112, \"accuracy\": 0.0, \"learning_rate\": 1.9505533425239733e-05, \"_runtime\": 28587.852586746216, \"_timestamp\": 1583740517.3787997, \"_step\": 12982}\\n', '{\"loss\": 0.3163151144981384, \"accuracy\": 0.0, \"learning_rate\": 1.9505495342478275e-05, \"_runtime\": 28590.035104751587, \"_timestamp\": 1583740519.5613177, \"_step\": 12983}\\n', '{\"loss\": 0.4993768870830536, \"accuracy\": 0.0, \"learning_rate\": 1.950545725971682e-05, \"_runtime\": 28592.222602128983, \"_timestamp\": 1583740521.748815, \"_step\": 12984}\\n', '{\"loss\": 0.30545700192451475, \"accuracy\": 0.0, \"learning_rate\": 1.950541917695536e-05, \"_runtime\": 28594.38809609413, \"_timestamp\": 1583740523.914309, \"_step\": 12985}\\n', '{\"loss\": 0.5104227840900422, \"accuracy\": 0.0, \"learning_rate\": 1.9505381094193905e-05, \"_runtime\": 28596.569601535797, \"_timestamp\": 1583740526.0958145, \"_step\": 12986}\\n', '{\"loss\": 0.5495247483253479, \"accuracy\": 0.0, \"learning_rate\": 1.9505343011432446e-05, \"_runtime\": 28598.76362991333, \"_timestamp\": 1583740528.2898428, \"_step\": 12987}\\n', '{\"loss\": 0.3636123687028885, \"accuracy\": 0.0, \"learning_rate\": 1.950530492867099e-05, \"_runtime\": 28600.941640853882, \"_timestamp\": 1583740530.4678538, \"_step\": 12988}\\n', '{\"loss\": 0.3498614400625229, \"accuracy\": 0.0, \"learning_rate\": 1.9505266845909532e-05, \"_runtime\": 28603.12463402748, \"_timestamp\": 1583740532.650847, \"_step\": 12989}\\n', '{\"loss\": 0.29560511112213134, \"accuracy\": 0.0, \"learning_rate\": 1.9505228763148074e-05, \"_runtime\": 28605.303024291992, \"_timestamp\": 1583740534.8292372, \"_step\": 12990}\\n', '{\"loss\": 0.3160191774368286, \"accuracy\": 0.0, \"learning_rate\": 1.9505190680386618e-05, \"_runtime\": 28607.465535640717, \"_timestamp\": 1583740536.9917486, \"_step\": 12991}\\n', '{\"loss\": 0.5232029914855957, \"accuracy\": 0.0, \"learning_rate\": 1.950515259762516e-05, \"_runtime\": 28609.64454483986, \"_timestamp\": 1583740539.1707578, \"_step\": 12992}\\n', '{\"loss\": 0.3517184555530548, \"accuracy\": 0.0, \"learning_rate\": 1.9505114514863704e-05, \"_runtime\": 28611.82610154152, \"_timestamp\": 1583740541.3523145, \"_step\": 12993}\\n', '{\"loss\": 0.4365436315536499, \"accuracy\": 0.0, \"learning_rate\": 1.9505076432102245e-05, \"_runtime\": 28614.008598804474, \"_timestamp\": 1583740543.5348117, \"_step\": 12994}\\n']}, 'wandb-summary.json': {'offset': 0, 'content': ['{\"accuracy\": 0.0, \"_timestamp\": 1583740543.5348117, \"learning_rate\": 1.9505076432102245e-05, \"loss\": 0.4365436315536499, \"_runtime\": 28614.008598804474, \"_step\": 12994}\\n']}}}}\n",
      "requests_with_retry encountered retryable exception: 500 Server Error: Internal Server Error for url: https://api.wandb.ai/files/neonbjb/nonint-transformers-torch/tcl01e2d/file_stream. args: ('https://api.wandb.ai/files/neonbjb/nonint-transformers-torch/tcl01e2d/file_stream',), kwargs: {'json': {'files': {'wandb-events.jsonl': {'offset': 937, 'content': ['{\"system.gpu.0.gpu\": 80.8, \"system.gpu.0.memory\": 57.47, \"system.gpu.0.memoryAllocated\": 92.13, \"system.gpu.0.temp\": 63.47, \"system.gpu.0.powerWatts\": 245.67, \"system.gpu.0.powerPercent\": 98.27, \"system.cpu\": 13.29, \"system.memory\": 26.39, \"system.disk\": 77.7, \"system.proc.memory.availableMB\": 48181.82, \"system.proc.memory.rssMB\": 7680.13, \"system.proc.memory.percent\": 11.74, \"system.proc.cpu.threads\": 60.0, \"system.network.sent\": 1243763939, \"system.network.recv\": 967369466, \"_wandb\": true, \"_timestamp\": 1583740544, \"_runtime\": 28754}\\n']}, 'wandb-history.jsonl': {'offset': 12981, 'content': ['{\"loss\": 0.6114494442939759, \"accuracy\": 0.0, \"learning_rate\": 1.950557150800119e-05, \"_runtime\": 28585.670660972595, \"_timestamp\": 1583740515.196874, \"_step\": 12981}\\n', '{\"loss\": 0.576430594921112, \"accuracy\": 0.0, \"learning_rate\": 1.9505533425239733e-05, \"_runtime\": 28587.852586746216, \"_timestamp\": 1583740517.3787997, \"_step\": 12982}\\n', '{\"loss\": 0.3163151144981384, \"accuracy\": 0.0, \"learning_rate\": 1.9505495342478275e-05, \"_runtime\": 28590.035104751587, \"_timestamp\": 1583740519.5613177, \"_step\": 12983}\\n', '{\"loss\": 0.4993768870830536, \"accuracy\": 0.0, \"learning_rate\": 1.950545725971682e-05, \"_runtime\": 28592.222602128983, \"_timestamp\": 1583740521.748815, \"_step\": 12984}\\n', '{\"loss\": 0.30545700192451475, \"accuracy\": 0.0, \"learning_rate\": 1.950541917695536e-05, \"_runtime\": 28594.38809609413, \"_timestamp\": 1583740523.914309, \"_step\": 12985}\\n', '{\"loss\": 0.5104227840900422, \"accuracy\": 0.0, \"learning_rate\": 1.9505381094193905e-05, \"_runtime\": 28596.569601535797, \"_timestamp\": 1583740526.0958145, \"_step\": 12986}\\n', '{\"loss\": 0.5495247483253479, \"accuracy\": 0.0, \"learning_rate\": 1.9505343011432446e-05, \"_runtime\": 28598.76362991333, \"_timestamp\": 1583740528.2898428, \"_step\": 12987}\\n', '{\"loss\": 0.3636123687028885, \"accuracy\": 0.0, \"learning_rate\": 1.950530492867099e-05, \"_runtime\": 28600.941640853882, \"_timestamp\": 1583740530.4678538, \"_step\": 12988}\\n', '{\"loss\": 0.3498614400625229, \"accuracy\": 0.0, \"learning_rate\": 1.9505266845909532e-05, \"_runtime\": 28603.12463402748, \"_timestamp\": 1583740532.650847, \"_step\": 12989}\\n', '{\"loss\": 0.29560511112213134, \"accuracy\": 0.0, \"learning_rate\": 1.9505228763148074e-05, \"_runtime\": 28605.303024291992, \"_timestamp\": 1583740534.8292372, \"_step\": 12990}\\n', '{\"loss\": 0.3160191774368286, \"accuracy\": 0.0, \"learning_rate\": 1.9505190680386618e-05, \"_runtime\": 28607.465535640717, \"_timestamp\": 1583740536.9917486, \"_step\": 12991}\\n', '{\"loss\": 0.5232029914855957, \"accuracy\": 0.0, \"learning_rate\": 1.950515259762516e-05, \"_runtime\": 28609.64454483986, \"_timestamp\": 1583740539.1707578, \"_step\": 12992}\\n', '{\"loss\": 0.3517184555530548, \"accuracy\": 0.0, \"learning_rate\": 1.9505114514863704e-05, \"_runtime\": 28611.82610154152, \"_timestamp\": 1583740541.3523145, \"_step\": 12993}\\n', '{\"loss\": 0.4365436315536499, \"accuracy\": 0.0, \"learning_rate\": 1.9505076432102245e-05, \"_runtime\": 28614.008598804474, \"_timestamp\": 1583740543.5348117, \"_step\": 12994}\\n']}, 'wandb-summary.json': {'offset': 0, 'content': ['{\"accuracy\": 0.0, \"_timestamp\": 1583740543.5348117, \"learning_rate\": 1.9505076432102245e-05, \"loss\": 0.4365436315536499, \"_runtime\": 28614.008598804474, \"_step\": 12994}\\n']}}}}\n",
      "requests_with_retry encountered retryable exception: 500 Server Error: Internal Server Error for url: https://api.wandb.ai/files/neonbjb/nonint-transformers-torch/tcl01e2d/file_stream. args: ('https://api.wandb.ai/files/neonbjb/nonint-transformers-torch/tcl01e2d/file_stream',), kwargs: {'json': {'files': {'wandb-events.jsonl': {'offset': 937, 'content': ['{\"system.gpu.0.gpu\": 80.8, \"system.gpu.0.memory\": 57.47, \"system.gpu.0.memoryAllocated\": 92.13, \"system.gpu.0.temp\": 63.47, \"system.gpu.0.powerWatts\": 245.67, \"system.gpu.0.powerPercent\": 98.27, \"system.cpu\": 13.29, \"system.memory\": 26.39, \"system.disk\": 77.7, \"system.proc.memory.availableMB\": 48181.82, \"system.proc.memory.rssMB\": 7680.13, \"system.proc.memory.percent\": 11.74, \"system.proc.cpu.threads\": 60.0, \"system.network.sent\": 1243763939, \"system.network.recv\": 967369466, \"_wandb\": true, \"_timestamp\": 1583740544, \"_runtime\": 28754}\\n']}, 'wandb-history.jsonl': {'offset': 12981, 'content': ['{\"loss\": 0.6114494442939759, \"accuracy\": 0.0, \"learning_rate\": 1.950557150800119e-05, \"_runtime\": 28585.670660972595, \"_timestamp\": 1583740515.196874, \"_step\": 12981}\\n', '{\"loss\": 0.576430594921112, \"accuracy\": 0.0, \"learning_rate\": 1.9505533425239733e-05, \"_runtime\": 28587.852586746216, \"_timestamp\": 1583740517.3787997, \"_step\": 12982}\\n', '{\"loss\": 0.3163151144981384, \"accuracy\": 0.0, \"learning_rate\": 1.9505495342478275e-05, \"_runtime\": 28590.035104751587, \"_timestamp\": 1583740519.5613177, \"_step\": 12983}\\n', '{\"loss\": 0.4993768870830536, \"accuracy\": 0.0, \"learning_rate\": 1.950545725971682e-05, \"_runtime\": 28592.222602128983, \"_timestamp\": 1583740521.748815, \"_step\": 12984}\\n', '{\"loss\": 0.30545700192451475, \"accuracy\": 0.0, \"learning_rate\": 1.950541917695536e-05, \"_runtime\": 28594.38809609413, \"_timestamp\": 1583740523.914309, \"_step\": 12985}\\n', '{\"loss\": 0.5104227840900422, \"accuracy\": 0.0, \"learning_rate\": 1.9505381094193905e-05, \"_runtime\": 28596.569601535797, \"_timestamp\": 1583740526.0958145, \"_step\": 12986}\\n', '{\"loss\": 0.5495247483253479, \"accuracy\": 0.0, \"learning_rate\": 1.9505343011432446e-05, \"_runtime\": 28598.76362991333, \"_timestamp\": 1583740528.2898428, \"_step\": 12987}\\n', '{\"loss\": 0.3636123687028885, \"accuracy\": 0.0, \"learning_rate\": 1.950530492867099e-05, \"_runtime\": 28600.941640853882, \"_timestamp\": 1583740530.4678538, \"_step\": 12988}\\n', '{\"loss\": 0.3498614400625229, \"accuracy\": 0.0, \"learning_rate\": 1.9505266845909532e-05, \"_runtime\": 28603.12463402748, \"_timestamp\": 1583740532.650847, \"_step\": 12989}\\n', '{\"loss\": 0.29560511112213134, \"accuracy\": 0.0, \"learning_rate\": 1.9505228763148074e-05, \"_runtime\": 28605.303024291992, \"_timestamp\": 1583740534.8292372, \"_step\": 12990}\\n', '{\"loss\": 0.3160191774368286, \"accuracy\": 0.0, \"learning_rate\": 1.9505190680386618e-05, \"_runtime\": 28607.465535640717, \"_timestamp\": 1583740536.9917486, \"_step\": 12991}\\n', '{\"loss\": 0.5232029914855957, \"accuracy\": 0.0, \"learning_rate\": 1.950515259762516e-05, \"_runtime\": 28609.64454483986, \"_timestamp\": 1583740539.1707578, \"_step\": 12992}\\n', '{\"loss\": 0.3517184555530548, \"accuracy\": 0.0, \"learning_rate\": 1.9505114514863704e-05, \"_runtime\": 28611.82610154152, \"_timestamp\": 1583740541.3523145, \"_step\": 12993}\\n', '{\"loss\": 0.4365436315536499, \"accuracy\": 0.0, \"learning_rate\": 1.9505076432102245e-05, \"_runtime\": 28614.008598804474, \"_timestamp\": 1583740543.5348117, \"_step\": 12994}\\n']}, 'wandb-summary.json': {'offset': 0, 'content': ['{\"accuracy\": 0.0, \"_timestamp\": 1583740543.5348117, \"learning_rate\": 1.9505076432102245e-05, \"loss\": 0.4365436315536499, \"_runtime\": 28614.008598804474, \"_step\": 12994}\\n']}}}}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12e482cef3a4d5faea92bad5a4f88f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation iteration', max=167.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795a019164074c76bf625df4f4e2702f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=109411.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf780cd1580e44ca8a8f20bbee049ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation iteration', max=167.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xfer_times = []\n",
    "forward_times = []\n",
    "backward_times = []\n",
    "opt_times = []\n",
    "sched_times = []\n",
    "\n",
    "def compute_accuracy(_pred, _true):\n",
    "    if num_labels > 0:\n",
    "        return np.sum(_pred == _true) / _pred.shape[0]\n",
    "    else:\n",
    "        return 0 # there is no accuracy with MSE.\n",
    "\n",
    "def clear_timers():\n",
    "    xfer_times.clear()\n",
    "    forward_times.clear()\n",
    "    backward_times.clear()\n",
    "    opt_times.clear()\n",
    "    sched_times.clear()\n",
    "\n",
    "def train_epoch(_model, _optimizer, _scheduler, _device, _dataloader, _logging_steps, _fp16=False):\n",
    "    clear_timers()\n",
    "    \n",
    "    _epoch_iterator = tqdm(_dataloader, desc=\"Iteration\")\n",
    "    _steps = 0\n",
    "    _tr_loss, _logging_loss = 0, 0\n",
    "    _accuracy_accum, _accuracy_last = 0, 0\n",
    "    _model.train()\n",
    "    for _step, _batch in enumerate(_epoch_iterator):\n",
    "        __s = time.time()\n",
    "        _batch = tuple(_t.to(_device) for _t in _batch)\n",
    "        _inputs = {\"input_ids\": _batch[0], \n",
    "                   \"attention_mask\": _batch[1], \n",
    "                   \"token_type_ids\": _batch[2], \n",
    "                   \"labels\": _batch[3]}\n",
    "        xfer_times.append(time.time() - __s)\n",
    "        \n",
    "        __s = time.time()\n",
    "        _outputs = _model(**_inputs)\n",
    "        forward_times.append(time.time() - __s)\n",
    "        \n",
    "        _loss = _outputs[0]\n",
    "        \n",
    "        backward_time = 0\n",
    "        __s = time.time()\n",
    "        if fp16:\n",
    "            with amp.scale_loss(_loss, _optimizer) as _scaled_loss:\n",
    "                _scaled_loss.backward()\n",
    "                backward_time = time.time() - __s\n",
    "        else:\n",
    "            _loss.backward()\n",
    "            backward_time = time.time() - __s\n",
    "        backward_times.append(backward_time)\n",
    "        \n",
    "        _tr_loss += _loss.item()\n",
    "        _logits_softmax = sp.special.softmax(_outputs[1].detach().cpu().softmax(-1).numpy(), axis=-1)\n",
    "        _accuracy_accum += compute_accuracy(np.argmax(_logits_softmax, axis=-1), _batch[3].cpu().numpy())\n",
    "        \n",
    "        if _fp16:\n",
    "            torch.nn.utils.clip_grad_norm_(amp.master_params(_optimizer), 1)\n",
    "        else:\n",
    "            torch.nn.utils.clip_grad_norm_(_model.parameters(), 1)\n",
    "        \n",
    "        __s = time.time()\n",
    "        _optimizer.step()\n",
    "        opt_times.append(time.time() - __s)\n",
    "        __s = time.time()\n",
    "        _scheduler.step()\n",
    "        sched_times.append(time.time() - __s)\n",
    "        _model.zero_grad()\n",
    "        _steps += 1\n",
    "        \n",
    "        # Log\n",
    "        if _steps % _logging_steps == 0:\n",
    "            _loss_scalar = (_tr_loss - _logging_loss) / _logging_steps\n",
    "            _accuracy_scalar = (_accuracy_accum - _accuracy_last) / _logging_steps\n",
    "            _logging_loss = _tr_loss\n",
    "            _accuracy_last = _accuracy_accum\n",
    "            _logs = {}\n",
    "            _logs[\"loss\"] = _loss_scalar\n",
    "            _logs[\"accuracy\"] = _accuracy_scalar\n",
    "            _logs[\"learning_rate\"] = _scheduler.get_lr()[0]\n",
    "            #print(json.dumps({**_logs, **{\"step\": _steps}}))\n",
    "            if do_wandb:\n",
    "                wandb.log(_logs)\n",
    "    \n",
    "def check_validation(_model, _device, _val_dataloader):\n",
    "    with torch.no_grad():\n",
    "        _val_iterator = tqdm(_val_dataloader, desc=\"Validation iteration\")\n",
    "        _loss = 0\n",
    "        _accuracy = 0\n",
    "        for _step, _batch in enumerate(_val_iterator):\n",
    "            _batch = tuple(_t.to(device) for _t in _batch)\n",
    "            _inputs = {\"input_ids\": _batch[0], \n",
    "                       \"attention_mask\": _batch[1], \n",
    "                       \"token_type_ids\": _batch[2], \n",
    "                       \"labels\": _batch[3]}\n",
    "            _outputs = model(**_inputs)\n",
    "            _loss += _outputs[0].item()\n",
    "            _logits_softmax = sp.special.softmax(_outputs[1].detach().cpu().softmax(-1).numpy(), axis=-1)\n",
    "            _accuracy += compute_accuracy(np.argmax(_logits_softmax, axis=-1), _batch[3].cpu().numpy())\n",
    "        _loss_computed = _loss/len(_val_dataloader)\n",
    "        _acc_computed = _accuracy/len(_val_dataloader)\n",
    "        print(\"Validation loss %f, accuracy=%f\" % (_loss_computed, _acc_computed))\n",
    "        if do_wandb:\n",
    "            wandb.log({'val_loss': _loss_computed, 'val_accuracy': _acc_computed})\n",
    "\n",
    "LOGGING_STEPS = 5\n",
    "EPOCHS = 2\n",
    "BATCH_SIZE = 24\n",
    "\n",
    "print(\"***** Running training *****\")\n",
    "print(\"  Num examples = %d\" % (len(train_dataset)))\n",
    "print(\"  Num Epochs = %d\" % (EPOCHS))\n",
    "print(\"  Total optimization steps = %d\" % (len(train_dataset)))\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "model.zero_grad()\n",
    "for _ in range(EPOCHS):\n",
    "    train_epoch(model, optimizer, scheduler, device, train_dataloader, LOGGING_STEPS, _fp16=True)\n",
    "    check_validation(model, device, val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def infer(_model, _sentence1, _sentence2=None, softmax=True):\n",
    "    features = [tokenizer.encode_plus(text=_sentence1, text_pair=_sentence2, max_length=128, pad_to_max_length=True)]\n",
    "    _inputs = {\"input_ids\": torch.tensor([f['input_ids'] for f in features], dtype=torch.long).to(device), \n",
    "               \"attention_mask\": torch.tensor([f['attention_mask'] for f in features], dtype=torch.long).to(device), \n",
    "               \"token_type_ids\": torch.tensor([f['token_type_ids'] for f in features], dtype=torch.long).to(device)}\n",
    "    with torch.no_grad():\n",
    "        _outputs = model(**_inputs)\n",
    "        if softmax: \n",
    "            return softmax(_outputs[0].cpu().numpy())\n",
    "        else:\n",
    "            return\n",
    "    \n",
    "print(infer(model, \"The man and the woman went to the store\", softmax=False))\n",
    "print(infer(model, \"I love it!\", softmax=False))\n",
    "print(infer(model, \"I hated it.\", softmax=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "tokenizer = transformers.AlbertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Save the model \n",
    "output_dir = os.path.join(\"c:/Users/jbetk/Documents/data/ml/saved_models\", \"sentiment_analysis_albert_pytorch\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "model_to_save = (\n",
    "    model.module if hasattr(model, \"module\") else model\n",
    ")  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(output_dir, \"model.pt\"))\n",
    "torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
    "torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save to torchscript\n",
    "dummy_input = [\n",
    "    torch.zeros(1, 128, dtype=torch.long),\n",
    "    torch.zeros(1, 128, dtype=torch.long),\n",
    "    torch.zeros(1, 128, dtype=torch.long),\n",
    "]\n",
    "__config = transformers.AlbertConfig.from_pretrained(output_dir, torchscript=True)\n",
    "__model = transformers.AlbertForSequenceClassification.from_pretrained(output_dir, config=__config)\n",
    "__model.eval()\n",
    "#model(*dummy_input)\n",
    "traced_model = torch.jit.trace(__model, dummy_input)\n",
    "torch.jit.save(traced_model, os.path.join(output_dir, \"torchscript_out.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
