{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import orjson\n",
    "import transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "import wandb\n",
    "import time\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "fp16 = True\n",
    "if fp16:\n",
    "    from apex import amp\n",
    "\n",
    "model_name = \"xlnet-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(input_file):\n",
    "    data = orjson.loads(open(input_file, \"rb\").read())\n",
    "    # Root data is a list of lists of features. The first-order list organizes the sequences into sets of like-length \n",
    "    # that can be batched together.\n",
    "    datasets = []\n",
    "    count = 0\n",
    "    for features in data:\n",
    "        # Each feature is a dictionary of a 'text' sequence and a 'title' sequence. The goal of this model is to\n",
    "        # predict the 'title' given the 'text'. Process them out together, the model trainer will do the rest of the\n",
    "        # work.\n",
    "        input_ids = torch.tensor([f['text']['input_ids'] for f in features], dtype=torch.long)\n",
    "        attention_mask = torch.tensor([f['text']['attention_mask'] for f in features], dtype=torch.float)\n",
    "        token_type_ids = torch.tensor([f['text']['token_type_ids'] for f in features], dtype=torch.long)\n",
    "        title_input_ids = torch.tensor([f['title']['input_ids'] for f in features], dtype=torch.long)\n",
    "        datasets.append(TensorDataset(input_ids, attention_mask, token_type_ids, title_input_ids))\n",
    "        count += len(features)\n",
    "    return datasets, count\n",
    "\n",
    "# Process dataset\n",
    "input_folder = \"C:\\\\Users\\\\jbetk\\\\Documents\\\\data\\\\ml\\\\title_prediction\\\\outputs\\\\\"\n",
    "train_datasets, total_train_data_sz = load_dataset(input_folder + \"processed.json\")\n",
    "val_datasets, total_val_data_sz = load_dataset(input_folder + \"validation.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://app.wandb.ai/neonbjb/nonint-transformers-torch\" target=\"_blank\">https://app.wandb.ai/neonbjb/nonint-transformers-torch</a><br/>\n                Run page: <a href=\"https://app.wandb.ai/neonbjb/nonint-transformers-torch/runs/pvf5dfog\" target=\"_blank\">https://app.wandb.ai/neonbjb/nonint-transformers-torch/runs/pvf5dfog</a><br/>\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "text": [
      "wandb: Wandb version 0.8.29 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# Load model\n",
    "tokenizer = transformers.XLNetTokenizer.from_pretrained(model_name)\n",
    "config = transformers.XLNetConfig.from_pretrained(model_name)\n",
    "model = transformers.XLNetLMHeadModel.from_pretrained(model_name, config=config)\n",
    "device = torch.device(\"cuda\")\n",
    "cpu = torch.device(\"cpu\")\n",
    "\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0,\n",
    "    },\n",
    "    {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "]\n",
    "optimizer = transformers.AdamW(optimizer_grouped_parameters, lr=2e-5, eps=1e-8)\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer, \n",
    "                                                         num_warmup_steps=0, num_training_steps=EPOCHS * total_train_data_sz)\n",
    "\n",
    "# Shift model to cuda & enable fp16 if applicable.\n",
    "model.to(device)\n",
    "if fp16:\n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n",
    "    \n",
    "# Initialize w&b logger\n",
    "do_wandb = True\n",
    "if do_wandb:\n",
    "    wandb.init(project=\"nonint-transformers-torch\",\\\n",
    "               name=\"xlnet_title_prediction_allin\",\\\n",
    "               config={\"dataset\": \"title_pred\"})\n",
    "    # There's something bugged about this, but it doesnt really seem to do much anyways. Apparently it enables some \n",
    "    # sort of gradient exploration map.\n",
    "    #wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "***** Running training *****\n",
      "Running validation..\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88fbd3f5e46c421b91ae41c1fd5b84a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22a9d2dbeba142e5a75424b3f9123ffe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7832bf1c52e14792a186bee649add499"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2fcb72fac9a0432d9c75216ed9cbb162"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81c532413d37484fa960d6f57711ad04"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2eaa31bd07564723bb4d608cea55067b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e780a83f48734a1f8bb068a160a0f8c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6fe538435ad248eca44146436c064bf1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10c7ba3c251a495cbf8934d748738408"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e43bd21cb3942cbbc84ec3cff080505"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b532c0d82d14edd8e4bdf903be5549a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb0ae1e916cb4a99b07c8259d24e9d11"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b39fb3a96ea14108b5388d676dd0c33f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c01de22fece24804b861affa68234cc4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8712f4f2d2dd45d1acf832283f311322"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24a238e2c1ca46ceb337d83b20f7b052"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc659a8ce01649dda6f94966e5f78d52"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4208354b7d874458a3fca769e66c4ef2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=8.0, style=ProgressStyle(description_widt…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0be688d07fc64ca79d432a606d8d0423"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-62d8c82ad0c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_datasets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mfull_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m         \u001b[0mtrain_sampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0mtrain_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_sampler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-62d8c82ad0c6>\u001b[0m in \u001b[0;36mfull_validate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_datasets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[0mval_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[0mcombined_val_steps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0mcombined_val_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-62d8c82ad0c6>\u001b[0m in \u001b[0;36mvalidate_epoch\u001b[1;34m(_model, _device, _dataloader, _max_title_len)\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0m__s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m             \u001b[0m_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;31m# Always accumulate loss across the last chunk, where it should be lowest. That's the goal of this model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\drive\\projects\\ml-notebooks\\pytorch-venv\\lib\\site-packages\\transformers\\modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, mems, perm_mask, target_mapping, token_type_ids, input_mask, head_mask, inputs_embeds, labels)\u001b[0m\n\u001b[0;32m   1050\u001b[0m             \u001b[0minput_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m             \u001b[0minputs_embeds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m         )\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\drive\\projects\\ml-notebooks\\pytorch-venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\drive\\projects\\ml-notebooks\\pytorch-venv\\lib\\site-packages\\transformers\\modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, mems, perm_mask, target_mapping, token_type_ids, input_mask, head_mask, inputs_embeds)\u001b[0m\n\u001b[0;32m    880\u001b[0m                 \u001b[0mmems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmems\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m                 \u001b[0mtarget_mapping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_mapping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m                 \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m             )\n\u001b[0;32m    884\u001b[0m             \u001b[0moutput_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\drive\\projects\\ml-notebooks\\pytorch-venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\drive\\projects\\ml-notebooks\\pytorch-venv\\lib\\site-packages\\transformers\\modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, output_h, output_g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask)\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[0mmems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmems\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[0mtarget_mapping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_mapping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m         )\n\u001b[0;32m    446\u001b[0m         \u001b[0moutput_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\drive\\projects\\ml-notebooks\\pytorch-venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\drive\\projects\\ml-notebooks\\pytorch-venv\\lib\\site-packages\\transformers\\modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, h, g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask)\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[1;31m# core attention ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             attn_vec_h = self.rel_attn_core(\n\u001b[1;32m--> 331\u001b[1;33m                 \u001b[0mq_head_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_head_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_head_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_head_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseg_mat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseg_mat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattn_mask_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m             )\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\drive\\projects\\ml-notebooks\\pytorch-venv\\lib\\site-packages\\transformers\\modeling_xlnet.py\u001b[0m in \u001b[0;36mrel_attn_core\u001b[1;34m(self, q_head, k_head_h, v_head_h, k_head_r, seg_mat, attn_mask, head_mask)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;31m# merge attention scores and perform masking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m         \u001b[0mattn_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mac\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbd\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mef\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mattn_mask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[1;31m# attn_score = attn_score * (1 - attn_mask) - 1e30 * attn_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\drive\\projects\\ml-notebooks\\pytorch-venv\\lib\\site-packages\\apex\\amp\\wrap.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0morig_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtypes\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'HalfTensor'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'FloatTensor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             new_args = utils.casted_args(cast_fn,\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.12 GiB (GPU 0; 11.00 GiB total capacity; 5.59 GiB already allocated; 674.74 MiB free; 8.04 GiB reserved in total by PyTorch)"
     ],
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.12 GiB (GPU 0; 11.00 GiB total capacity; 5.59 GiB already allocated; 674.74 MiB free; 8.04 GiB reserved in total by PyTorch)",
     "output_type": "error"
    }
   ],
   "source": [
    "preprocess_times = []\n",
    "xfer_times = []\n",
    "forward_times = []\n",
    "backward_times = []\n",
    "opt_times = []\n",
    "sched_times = []\n",
    "\n",
    "def clear_timers():\n",
    "    xfer_times.clear()\n",
    "    forward_times.clear()\n",
    "    backward_times.clear()\n",
    "    opt_times.clear()\n",
    "    sched_times.clear()\n",
    "\n",
    "def prepare_inputs(_batched_inputs, _max_title_len, _device):\n",
    "    with torch.no_grad():\n",
    "        _input_ids = _batched_inputs[0]\n",
    "        _attention_masks = _batched_inputs[1]\n",
    "        _token_types = _batched_inputs[2]\n",
    "        \n",
    "        _batch_sz = _input_ids.shape[0]\n",
    "        _seq_len = _input_ids.shape[-1]\n",
    "        \n",
    "        # These tensors will be used to append on to the input tensors where the prediction will occur.\n",
    "        _input_mask_tensor = torch.full((_batch_sz, _max_title_len), tokenizer.mask_token_id, dtype=torch.long)\n",
    "        _ones_float_tensor_for_title = torch.ones((_batch_sz, _max_title_len), dtype=torch.float)\n",
    "        _ones_long_tensor_for_title = torch.ones((_batch_sz, _max_title_len), dtype=torch.long)\n",
    "        \n",
    "        # For the input_ids, append on _max_title_len masks.\n",
    "        _input_ids = torch.cat([_input_ids, _input_mask_tensor], dim=-1)\n",
    "        # For the attention mask, just add all 1s because this is not padding.\n",
    "        _attention_masks = torch.cat([_attention_masks, _ones_float_tensor_for_title], dim=-1)\n",
    "        # For token type IDs, also all 1s since this is the \"second sentence\".\n",
    "        _token_types = torch.cat([_token_types, _ones_long_tensor_for_title], dim=-1)\n",
    "    \n",
    "        # Create a target mapping that will be used for all inputs, since they all follow a similar format.\n",
    "        _target_mapping = torch.zeros((_batch_sz, _max_title_len, _seq_len + _max_title_len), dtype=torch.float)\n",
    "        for i in range(_max_title_len):\n",
    "            for b in range(_batch_sz):\n",
    "                _target_mapping[b][i][_seq_len + i] = 1\n",
    "        \n",
    "        _inputs = {\"input_ids\": _input_ids, \n",
    "              \"attention_mask\": _attention_masks, \n",
    "              \"token_type_ids\": _token_types,\n",
    "              \"target_mapping\": _target_mapping,\n",
    "              \"labels\": _batched_inputs[3]}\n",
    "        \n",
    "        # Don't forget to send all these tensors to the device.\n",
    "        __s = time.time()\n",
    "        for i, (k,v) in enumerate(_inputs.items()):\n",
    "            _inputs[k] = v.to(_device)\n",
    "        xfer_times.append(time.time() - __s)\n",
    "        \n",
    "    return _inputs\n",
    "\n",
    "def train_epoch(_model, _optimizer, _scheduler, _device, _dataloader, _max_title_len, _fp16):\n",
    "    clear_timers()\n",
    "    \n",
    "    _epoch_iterator = tqdm(_dataloader, desc=\"Iteration\")\n",
    "    _steps = 0\n",
    "    _tr_loss, _logging_loss = 0, 0\n",
    "    _accuracy_accum, _accuracy_last = 0, 0\n",
    "    _model.train()\n",
    "    \n",
    "    for _step, _batch in enumerate(_epoch_iterator):\n",
    "        __s = time.time()\n",
    "        _inputs = prepare_inputs(_batch, _max_title_len, _device)\n",
    "        preprocess_times.append(time.time() - __s)\n",
    "        \n",
    "        # Forward\n",
    "        __s = time.time()\n",
    "        _loss, _logits = _model.forward(**_inputs)\n",
    "        forward_times.append(time.time() - __s)            \n",
    "        \n",
    "        # Backwards\n",
    "        __s = time.time()\n",
    "        if fp16:\n",
    "            with amp.scale_loss(_loss, _optimizer) as _scaled_loss:\n",
    "                _scaled_loss.backward()\n",
    "                backward_time = time.time() - __s\n",
    "        else:\n",
    "            _loss.backward()\n",
    "            backward_time = time.time() - __s\n",
    "        backward_times.append(backward_time)\n",
    "        \n",
    "        # Update weights\n",
    "        if _fp16:\n",
    "            torch.nn.utils.clip_grad_norm_(amp.master_params(_optimizer), 1)\n",
    "        else:\n",
    "            torch.nn.utils.clip_grad_norm_(_model.parameters(), 1)\n",
    "        __s = time.time()\n",
    "        _optimizer.step()\n",
    "        opt_times.append(time.time() - __s)\n",
    "        __s = time.time()\n",
    "        _scheduler.step()\n",
    "        sched_times.append(time.time() - __s)\n",
    "        \n",
    "        _model.zero_grad()\n",
    "        \n",
    "        # Always accumulate loss across the last chunk, where it should be lowest. That's the goal of this model.\n",
    "        _steps += 1\n",
    "        _tr_loss += _loss.item()\n",
    "        \n",
    "        # Always log.\n",
    "        _loss_scalar = (_tr_loss - _logging_loss)\n",
    "        _logging_loss = _tr_loss\n",
    "        _logs = {}\n",
    "        _logs[\"loss\"] = _loss_scalar\n",
    "        _logs[\"learning_rate\"] = _scheduler.get_lr()[0]\n",
    "        if do_wandb:\n",
    "            wandb.log(_logs)\n",
    "\n",
    "\n",
    "def validate_epoch(_model, _device, _dataloader, _max_title_len):\n",
    "    _epoch_iterator = tqdm(_dataloader, desc=\"Iteration\")\n",
    "    _steps = 0\n",
    "    _tr_loss, _logging_loss = 0, 0\n",
    "    _accuracy_accum, _accuracy_last = 0, 0\n",
    "    _model.train()\n",
    "    for _step, _batch in enumerate(_epoch_iterator):\n",
    "        _inputs = prepare_inputs(_batch, _max_title_len, _device)\n",
    "        __s = time.time()\n",
    "        with torch.no_grad():\n",
    "            _loss, _logits = _model.forward(**_inputs)\n",
    "        \n",
    "        # Always accumulate loss across the last chunk, where it should be lowest. That's the goal of this model.\n",
    "        _steps += 1\n",
    "        _tr_loss += _loss.item()\n",
    "    return _tr_loss, _steps\n",
    "\n",
    "print(\"***** Running training *****\")\n",
    "\n",
    "def full_validate():\n",
    "    print(\"Running validation..\")\n",
    "    combined_val_steps, combined_val_loss = 0, 0\n",
    "    for val_dataset in val_datasets:\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "        l, s = validate_epoch(model, device, val_dataloader, 64)\n",
    "        combined_val_steps += s\n",
    "        combined_val_loss += l\n",
    "        \n",
    "    _logs = {}\n",
    "    _logs[\"val_loss\"] = combined_val_loss / combined_val_steps\n",
    "    if do_wandb:\n",
    "        wandb.log(_logs)\n",
    "    print(\"Validation loss averaged over %i steps: %f\" % (int(combined_val_steps), combined_val_loss / combined_val_steps))\n",
    "\n",
    "model.zero_grad()\n",
    "for _ in range(EPOCHS):\n",
    "    for train_dataset in train_datasets:\n",
    "        full_validate()\n",
    "        train_sampler = RandomSampler(train_dataset)\n",
    "        train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "        \n",
    "        train_epoch(model, optimizer, scheduler, device, train_dataloader, 64, fp16)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Save the model \n",
    "output_dir = os.path.join(\"c:/Users/jbetk/Documents/data/ml/saved_models\", \"xlnet_title_generation\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "model_to_save = (\n",
    "    model.module if hasattr(model, \"module\") else model\n",
    ")  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(output_dir, \"model.pt\"))\n",
    "torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
    "torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
    "\n",
    "print(\"Save completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}