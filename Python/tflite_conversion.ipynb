{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66892912"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "saved_model_dir = \"c:/Users/jbetk/Documents/data/ml/saved_models/sentiment_mse_distilbert_yelp_amazon/\"\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "converter.experimental_new_converter = True\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "open(saved_model_dir + \"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input array not provided for operation 'reshape'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c2c1ee381bd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minterpreter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInterpreter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msaved_model_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/converted_model.tflite\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_input_details\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\drive\\projects\\ml-notebooks\\pycharm-venv\\lib\\site-packages\\tensorflow_core\\lite\\python\\interpreter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_path, model_content, experimental_delegates)\u001b[0m\n\u001b[0;32m    205\u001b[0m       self._interpreter = (\n\u001b[0;32m    206\u001b[0m           _interpreter_wrapper.InterpreterWrapper_CreateWrapperCPPFromFile(\n\u001b[1;32m--> 207\u001b[1;33m               model_path, self._custom_op_registerers))\n\u001b[0m\u001b[0;32m    208\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Failed to open {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input array not provided for operation 'reshape'.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=saved_model_dir + \"/converted_model.tflite\")\n",
    "print(interpreter.get_input_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'input_1_11:0' shape=(None, 128) dtype=int32>, <tf.Tensor 'input_2_9:0' shape=(None, 128) dtype=int32>]\n",
      "[<tf.Tensor 'tf_roberta_model_1/Identity:0' shape=(None, 128, 768) dtype=float32>, <tf.Tensor 'tf_roberta_model_1/Identity_1:0' shape=(None, 768) dtype=float32>]\n"
     ]
    },
    {
     "ename": "ConverterError",
     "evalue": "See console for info.\n2020-02-03 14:16:20.869205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\n2020-02-03 14:16:25.853657: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Cumsum\n2020-02-03 14:16:25.854123: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.854715: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.855259: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.855869: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.856324: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.856863: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.857394: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.857914: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.858543: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.859107: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.859552: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.860084: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:26.060782: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1517 operators, 2651 arrays (0 quantized)\n2020-02-03 14:16:26.149298: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1517 operators, 2651 arrays (0 quantized)\n2020-02-03 14:16:26.149831: F tensorflow/lite/toco/graph_transformations/resolve_strided_slice_attributes.cc:95] Check failed: start_indices_size <= num_input_axes (4 vs. 2)StridedSlice op requires no more than 2 start indices\nFatal Python error: Aborted\n\nCurrent thread 0x000013c4 (most recent call first):\n  File \"c:\\drive\\projects\\ml-notebooks\\pycharm-venv\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 52 in execute\n  File \"c:\\drive\\projects\\ml-notebooks\\pycharm-venv\\lib\\site-packages\\absl\\app.py\", line 250 in _run_main\n  File \"c:\\drive\\projects\\ml-notebooks\\pycharm-venv\\lib\\site-packages\\absl\\app.py\", line 299 in run\n  File \"c:\\drive\\projects\\ml-notebooks\\pycharm-venv\\lib\\site-packages\\tensorflow_core\\python\\platform\\app.py\", line 40 in run\n  File \"c:\\drive\\projects\\ml-notebooks\\pycharm-venv\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 89 in main\n  File \"C:\\drive\\projects\\ml-notebooks\\pycharm-venv\\Scripts\\toco_from_protos.exe\\__main__.py\", line 9 in <module>\n  File \"C:\\python\\lib\\runpy.py\", line 85 in _run_code\n  File \"C:\\python\\lib\\runpy.py\", line 193 in _run_module_as_main\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1f63532e8b87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_new_converter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mtflite_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"distilbert-squad-384.tflite\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\drive\\projects\\ml-notebooks\\pycharm-venv\\lib\\site-packages\\tensorflow_core\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[0moutput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         **converter_kwargs)\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_calibration_quantize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\drive\\projects\\ml-notebooks\\pycharm-venv\\lib\\site-packages\\tensorflow_core\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[1;34m(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\u001b[0m\n\u001b[0;32m    447\u001b[0m       \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdebug_info_str\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m       enable_mlir_converter=enable_mlir_converter)\n\u001b[0m\u001b[0;32m    450\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\drive\\projects\\ml-notebooks\\pycharm-venv\\lib\\site-packages\\tensorflow_core\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[1;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[0;32m    198\u001b[0m       \u001b[0mstdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m       \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mConverterError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"See console for info.\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;31m# Must manually cleanup files.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConverterError\u001b[0m: See console for info.\n2020-02-03 14:16:20.869205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\n2020-02-03 14:16:25.853657: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Cumsum\n2020-02-03 14:16:25.854123: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.854715: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.855259: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.855869: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.856324: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.856863: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.857394: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.857914: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.858543: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.859107: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.859552: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:25.860084: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Erf\n2020-02-03 14:16:26.060782: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1517 operators, 2651 arrays (0 quantized)\n2020-02-03 14:16:26.149298: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1517 operators, 2651 arrays (0 quantized)\n2020-02-03 14:16:26.149831: F tensorflow/lite/toco/graph_transformations/resolve_strided_slice_attributes.cc:95] Check failed: start_indices_size <= num_input_axes (4 vs. 2)StridedSlice op requires no more than 2 start indices\nFatal Python error: Aborted\n\nCurrent thread 0x000013c4 (most recent call first):\n  File \"c:\\drive\\projects\\ml-notebooks\\pycharm-venv\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 52 in execute\n  File \"c:\\drive\\projects\\ml-notebooks\\pycharm-venv\\lib\\site-packages\\absl\\app.py\", line 250 in _run_main\n  File \"c:\\drive\\projects\\ml-notebooks\\pycharm-venv\\lib\\site-packages\\absl\\app.py\", line 299 in run\n  File \"c:\\drive\\projects\\ml-notebooks\\pycharm-venv\\lib\\site-packages\\tensorflow_core\\python\\platform\\app.py\", line 40 in run\n  File \"c:\\drive\\projects\\ml-notebooks\\pycharm-venv\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 89 in main\n  File \"C:\\drive\\projects\\ml-notebooks\\pycharm-venv\\Scripts\\toco_from_protos.exe\\__main__.py\", line 9 in <module>\n  File \"C:\\python\\lib\\runpy.py\", line 85 in _run_code\n  File \"C:\\python\\lib\\runpy.py\", line 193 in _run_module_as_main\n\n\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFRobertaModel\n",
    "\n",
    "model = TFRobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "input_spec = [tf.TensorSpec([1, 128], tf.int32), tf.TensorSpec([1, 128], tf.int32)]\n",
    "model._set_inputs(input_spec, training=False)\n",
    "\n",
    "print(model.inputs)\n",
    "print(model.outputs)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# For normal conversion:\n",
    "#converter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "\n",
    "# For conversion with FP16 quantization:\n",
    "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "# converter.target_spec.supported_types = [tf.float16]\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# converter.experimental_new_converter = True\n",
    "\n",
    "# For conversion with hybrid quantization:\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "converter.experimental_new_converter = True\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(\"distilbert-squad-384.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
